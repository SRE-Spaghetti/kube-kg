# Story 2.3: Initial Synchronization Processor

## Status
- Ready for Review

## Story
**As a** developer,
**I want** a processor that orchestrates the full synchronization of Kubernetes resources into Neo4j,
**so that** I can populate the graph with the initial state of the cluster.

## Acceptance Criteria
1. An `InitialSync` function is created that takes the `KubeviewClient` and `Neo4jClient` as dependencies.
2. The function first calls the `KubeviewClient` to get all resources from all namespaces.
3. For each resource, it uses the mapping logic from Story 2.2 to generate nodes and relationships.
4. It then uses the `Neo4jClient` to execute idempotent `MERGE` queries to create/update the nodes and relationships in the database.
5. The entire synchronization process is wrapped in a single OpenTelemetry trace.
6. All Neo4j write operations for a given namespace are executed within a single transaction.
7. An integration test verifies that running `InitialSync` against a mock KubeView API correctly populates a test Neo4j database with the expected nodes and relationships.

## Tasks / Subtasks
- [x] Task 1: Implement Initial Sync Function (AC: 1, 2, 3, 4)
  - [x] Create a new package `internal/processor`.
  - [x] In `internal/processor/processor.go`, implement the `InitialSync` function.
  - [x] The function should loop through each namespace, fetch its resources, and then iterate through the resources to map them to nodes and relationships.
- [x] Task 2: Add Transaction Management (AC: 6)
  - [x] Ensure that all the `MERGE` queries for a single namespace are executed within a single Neo4j transaction.
- [x] Task 3: Add OpenTelemetry Instrumentation (AC: 5)
  - [x] Create a single parent span that covers the entire `InitialSync` operation.
- [x] Task 4: Write Integration Tests (AC: 7)
  - [x] Create `internal/processor/processor_test.go`.
  - [x] Write an integration test that uses a mock KubeView client and a Testcontainers Neo4j instance.
  - [x] The test should verify that the processor correctly fetches, maps, and persists the data.

## Dev Notes

### File Locations & Structure
- `internal/processor/processor.go` (New)
- `internal/processor/processor_test.go` (New)

[Source: docs/architecture/09-source-tree.md]

### Component Dependencies
- The `processor` component depends on the `kubeview`, `neo4j`, `graph`, and `observability` components.

[Source: docs/architecture/05-components.md]

### Data Consistency
- All Neo4j writes must use `MERGE` to ensure idempotency.
- Writes for a given namespace must be transactional.

[Source: docs/architecture/11-error-handling-strategy.md]

### Coding Standards
- **Language:** Go 1.24.6
- **Context:** `context.Context` must be passed to all functions that interact with external systems.

[Source: docs/architecture/12-coding-standards.md]

### Testing
- **Integration Tests:** This story requires an integration test that spins up a real Neo4j database using Testcontainers and mocks the KubeView API.
- **Test Data:** Use JSON fixtures for the mock KubeView API.

[Source: docs/architecture/13-test-strategy-and-standards.md]

## Dev Agent Record

### File List
- `internal/processor/processor.go`
- `internal/processor/processor_test.go`
- `internal/neo4j/client.go`
- `internal/neo4j/client_test.go`

### Definition of Done Checklist

1. **Requirements Met:**
   - [x] All functional requirements specified in the story are implemented.
   - [x] All acceptance criteria defined in the story are met.

2. **Coding Standards & Project Structure:**
   - [x] All new/modified code strictly adheres to `Operational Guidelines`.
   - [x] All new/modified code aligns with `Project Structure` (file locations, naming, etc.).
   - [x] Adherence to `Tech Stack` for technologies/versions used.
   - [x] Adherence to `Api Reference` and `Data Models`.
   - [x] Basic security best practices applied.
   - [x] No new linter errors or warnings introduced.
   - [N/A] Code is well-commented where necessary.

3. **Testing:**
   - [N/A] All required unit tests implemented.
   - [x] All required integration tests implemented.
   - [x] All tests pass successfully.
   - [N/A] Test coverage meets project standards.

4. **Functionality & Verification:**
   - [x] Functionality has been manually verified by the developer.
   - [x] Edge cases and potential error conditions considered and handled gracefully.

5. **Story Administration:**
   - [x] All tasks within the story file are marked as complete.
   - [x] Any clarifications or decisions made during development are documented.
   - [x] The story wrap up section has been completed.

6. **Dependencies, Build & Configuration:**
   - [x] Project builds successfully without errors.
   - [x] Project linting passes.
   - [x] Any new dependencies added were pre-approved.
   - [x] New dependencies are recorded in project files.
   - [x] No known security vulnerabilities introduced by new dependencies.
   - [N/A] New environment variables or configurations are documented.

7. **Documentation (If Applicable):**
   - [x] Relevant inline code documentation is complete.
   - [N/A] User-facing documentation updated.
   - [N/A] Technical documentation updated.

### Final Confirmation
- [x] I, the Developer Agent, confirm that all applicable items above have been addressed.



## Change Log

| Date       | Version | Description                | Author |
| :--------- | :------ | :------------------------- | :----- |
| 2025-09-18 | 1.0     | Initial draft of the story. | Bob    |

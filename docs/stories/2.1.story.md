# Story 2.1: KubeView API Client

## Status
- Ready for Review

## Story
**As a** developer,
**I want** a client to interact with the KubeView REST API,
**so that** I can fetch the list of namespaces and all resources within them.

## Acceptance Criteria
1. A `KubeviewClient` struct is created with an `http.Client`.
2. Go structs are defined to accurately represent the JSON responses from `/api/namespaces` and `/api/fetch/{namespace}`, based on the `openapi.yaml`.
3. A `ListNamespaces` method is implemented that correctly calls the `/api/namespaces` endpoint and unmarshals the response.
4. A `FetchNamespaceResources` method is implemented that correctly calls the `/api/fetch/{namespace}` endpoint and unmarshals the response.
5. The client is instrumented with OpenTelemetry to trace the API calls.
6. Integration tests are written to verify the client can successfully connect to a KubeView instance and parse the responses.

## Tasks / Subtasks
- [x] Task 1: Define KubeView API Data Structures (AC: 2)
  - [x] Create a new package `internal/kubeview`.
  - [x] In `internal/kubeview/client.go`, define Go structs for the `Namespace` and `Resource` objects based on the `openapi.yaml` and the data models.
- [x] Task 2: Implement KubeView Client (AC: 1, 3, 4)
  - [x] In `internal/kubeview/client.go`, define a `Client` struct that contains a configured `http.Client`.
  - [x] Implement a `NewClient()` function that returns a `*Client`.
  - [x] Implement the `ListNamespaces()` method.
  - [x] Implement the `FetchNamespaceResources()` method.
- [x] Task 3: Add OpenTelemetry Instrumentation (AC: 5)
  - [x] Wrap the external HTTP calls in `ListNamespaces` and `FetchNamespaceResources` with OpenTelemetry spans.
- [x] Task 4: Write Integration Tests (AC: 6)
  - [x] Create `internal/kubeview/client_test.go`.
  - [x] Write integration tests that use a mock HTTP server to test the client's functionality.
  - [x] Verify that the client correctly unmarshals the JSON responses.

## Dev Notes

### File Locations & Structure
- `internal/kubeview/client.go` (New)
- `internal/kubeview/client_test.go` (New)

[Source: docs/architecture/09-source-tree.md]

### API Specification
- The client should conform to the OpenAPI spec defined in `openapi.yaml`. While the story does not require reading this file, the acceptance criteria are based on it.

[Source: docs/prd/epic-2-initial-graph-synchronization.md]

### Error Handling
- API errors from KubeView (e.g., 4xx, 5xx responses) should be wrapped in custom error types (e.g., `ErrKubeViewConnection`).
- Use a reasonable timeout on the `http.Client` (e.g., 30 seconds).

[Source: docs/architecture/11-error-handling-strategy.md]

### Coding Standards
- **Language:** Go 1.24.6
- **Context:** `context.Context` must be passed as the first argument to all methods that make network requests.
- **Logging:** Use `slog` for logging any important information or errors.

[Source: docs/architecture/12-coding-standards.md]

### Testing
- **Integration Tests:** Use a mock HTTP server to serve static JSON fixtures. Test data should be stored in a `/testdata` directory.
- **Framework:** Go `testing` package.

[Source: docs/architecture/13-test-strategy-and-standards.md]

## Dev Agent Record

### File List
- `internal/kubeview/client.go`
- `internal/kubeview/client_test.go`

### Definition of Done Checklist

1. **Requirements Met:**
   - [x] All functional requirements specified in the story are implemented.
   - [x] All acceptance criteria defined in the story are met.

2. **Coding Standards & Project Structure:**
   - [x] All new/modified code strictly adheres to `Operational Guidelines`.
   - [x] All new/modified code aligns with `Project Structure` (file locations, naming, etc.).
   - [x] Adherence to `Tech Stack` for technologies/versions used.
   - [x] Adherence to `Api Reference` and `Data Models`.
   - [x] Basic security best practices applied.
   - [x] No new linter errors or warnings introduced.
   - [N/A] Code is well-commented where necessary.

3. **Testing:**
   - [N/A] All required unit tests implemented.
   - [x] All required integration tests implemented.
   - [x] All tests pass successfully.
   - [N/A] Test coverage meets project standards.

4. **Functionality & Verification:**
   - [x] Functionality has been manually verified by the developer.
   - [x] Edge cases and potential error conditions considered and handled gracefully.

5. **Story Administration:**
   - [x] All tasks within the story file are marked as complete.
   - [x] Any clarifications or decisions made during development are documented.
   - [x] The story wrap up section has been completed.

6. **Dependencies, Build & Configuration:**
   - [x] Project builds successfully without errors.
   - [x] Project linting passes.
   - [x] Any new dependencies added were pre-approved.
   - [x] New dependencies are recorded in project files.
   - [x] No known security vulnerabilities introduced by new dependencies.
   - [N/A] New environment variables or configurations are documented.

7. **Documentation (If Applicable):**
   - [x] Relevant inline code documentation is complete.
   - [N/A] User-facing documentation updated.
   - [N/A] Technical documentation updated.

### Final Confirmation
- [x] I, the Developer Agent, confirm that all applicable items above have been addressed.



## Change Log

| Date       | Version | Description                | Author |
| :--------- | :------ | :------------------------- | :----- |
| 2025-09-18 | 1.0     | Initial draft of the story. | Bob    |
